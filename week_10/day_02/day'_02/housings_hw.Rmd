---
title: "Homework - features and elements of multiple regression"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
```

<hr>

# MVP

```{r}
library(tidyverse)
library(fastDummies)
library(mosaicData)
library(tidyverse)
library(janitor)
library(GGally)
library(ggfortify)
library(mosaic)
```


<br>

1. Load the `housing_prices.csv` data set and undertake an initial exploration of the data. You will find details on the data set on the relevant [Kaggle page](https://www.kaggle.com/camnugent/california-housing-prices)


```{r}

housing_prices <- read_csv("data/housing_prices.csv")

housing_prices %>% 
  summarise(across(.fns = ~ sum(is.na(.x))))


```


<br>

2. We expect the `total_rooms` of houses to be strongly correlated with `total_bedrooms`. Use `ggpairs()` to investigate correlations between these two variables.

```{r}
housing_prices %>% 
  select(total_rooms, total_bedrooms) %>% 
  ggpairs()

```


<br> 

3. So, we do find significant correlations. Let's drop `total_bedrooms` from the dataset, and use only `total_rooms` going forward.

```{r}
housing_prices_filter <- housing_prices %>% 
  select(-total_bedrooms)

```


<br>

4. We are interested in developing a regression model for the `median_house_value` of a house in terms of the possible predictor variables in the dataset. 


  i. Use `ggpairs()` to investigate correlations between `median_house_value` and the predictors (this may take a while to run, don't worry, make coffee or something).
  
  
```{r}
housing_prices_filter %>% 
  ggpairs(progress = F)
```
  

  ii. Perform further `ggplot` visualisations of any significant correlations you find.
  
  
  median_house_vaule vs median_income
  
```{r}

housing_prices_filter %>% 
  ggplot(aes(y = median_house_value, x = median_income)) +
  geom_point() +
  geom_smooth(method = "lm", se = F) 

```
  

<br>

5. Shortly we may try a regression model to fit the categorical predictor `ocean_proximity`. Investigate the level of `ocean_proximity` predictors. How many dummy variables do you expect to get from it?

four 

```{r}

housing_prices_dummy <- housing_prices_filter %>% 
  dummy_cols(select_columns = "ocean_proximity",
             remove_selected_columns = TRUE, remove_most_frequent_dummy = TRUE)

```

    
<br>
 
6. Start with simple linear regression. Regress `median_house_value` on `median_income` and check the regression diagnostics.

```{r}

model1 <- lm(median_house_value ~ median_income, housing_prices_dummy)

summary(model1)

```
```{r}
residuals <- residuals(model1)

qqnorm(residuals)
qqline(residuals)

autoplot(model1)
```

<br> 

7. Add another predictor of your choice. Check your assumptions, diagnostics, and interpret the model.

```{r}

model2 <- lm(median_house_value ~ median_income + housing_median_age, housing_prices_dummy)

summary(model2)
autoplot(model2)
```
-  Residuals vs. Fitted Values: has straight line so indicating constant variance 
-  QQ plot shows roughly a straight residuals are normally distributed
-  for the vaule of a house the the income goes up 42420


changing the ref dummy 

```{r}




grades2 <- grades %>% 
  mutate(subject2 = as.factor(subject), .after = subject,
         subject3 = relevel(subject2, 'english'))

lm4 <- lm(final ~ assignment + subject2, grades2)
lm5 <- lm(final ~ assignment + subject3, grades2)
summary(lm4)
summary(lm5)


dummy_cols(grades, remove_first_dummy = FALSE) #but nit nice


```

# Extension
    
<br>

8. Try adding an interaction between `log(median_income)` and your chosen categorical predictor. Do you think this interaction term is statistically justified?

<br>

9. Find and plot an appropriate visualisation to show the effect of this interaction



