---
title: 'Manual model development'
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---
```{r}

library(tidyverse)
library(modelr)
library(GGally)
library(ggfortify)

```


# MVP

You are given a set of data on housing sale prices for the last few years in King County (near Seattle) between May 2014 and May 2015.

<br>
<div class="emphasis">
We want you to build an **explanatory model** for the `price` of housing in King County, i.e. an interpretable model in which the included variables are statistically justifiable.

The variable definitions are:

`id` - Unique ID for each home sold  
`date` - Date of the home sale  
`price` - Price of each home sold  
`bedrooms` - Number of bedrooms  
`bathrooms` - Number of bathrooms, where .5 accounts for a room with a toilet but no shower  
`sqft_living` - Square footage of the apartments interior living space  
`sqft_lot` - Square footage of the land space  
`floors` - Number of floors  
`waterfront` - A dummy variable for whether the apartment was overlooking the waterfront or not  
`view` - An index from 0 to 4 of how good the view of the property was  
`condition` - An index from 1 to 5 on the condition of the apartment  
`grade` - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design  
`sqft_above` - The square footage of the interior housing space that is above ground level  
`sqft_basement` - The square footage of the interior housing space that is below ground level  
`yr_built` - The year the house was initially built  
`yr_renovated` - The year of the houseâ€™s last renovation  
`zipcode` - What zipcode area the house is in  
`lat` - Lattitude  
`long` - Longitude  
`sqft_living15` - The square footage of interior housing living space for the nearest 15 neighbors  
`sqft_lot15` - The square footage of the land lots of the nearest 15 neighbors  
</div>
<br>


# Question 1

Tidy up the data ready for regression:

    * You might like to think about removing some or all of `date`, `id`, `sqft_living15`, `sqft_lot15` and `zipcode` (`lat` and `long` provide a better measure of location in any event).
    * Have a think about how to treat `waterfront`. Should we convert its type?
    * We converted `yr_renovated` into a `renovated` logical variable, indicating whether the property had ever been renovated. You may wish to do the same.
    * Have a think about how to treat `view`, `condition` and `grade`? Are they interval or categorical ordinal data types?


```{r}
housing_sales <- read_csv("data/kc_house_data.csv")

```

```{r}
housing_sales_clean <- housing_sales %>% 
  select(-c(date, id, sqft_living, sqft_living15, sqft_lot15, zipcode)) 
```

```{r}
housing_sales_clean <- housing_sales_clean %>% 
  mutate(waterfront = as_factor(waterfront))
```

```{r}
housing_sales_clean <- housing_sales_clean %>% 
  mutate(yr_renovated = as.logical(yr_renovated)) %>% 
  mutate(view = as_factor(view)) %>% 
  mutate(condition = as_factor(condition)) %>%
  mutate(grade = as_factor(grade))
```

Have a think about how to treat `view`, `condition` and `grade`? Are they interval or categorical ordinal data types?

All categorical?


# Question 2

Check for aliased variables using the `alias()` function (this takes in a formula object and a data set). [**Hint** - formula `price ~ .` says 'price varying with all predictors', this is a suitable input to `alias()`]. Remove variables that lead to an alias. Check the 'Elements of multiple regression' lesson for a dropdown containing further information on finding aliased variables in a dataset.


```{r}
alias(lm(price ~ ., housing_sales_clean))
```


# Question 3

Systematically build a regression model containing up to **four** main effects (remember, a main effect is just a single predictor with coefficient), testing the regression diagnostics as you go
    * splitting datasets into numeric and non-numeric columns might help `ggpairs()` run in manageable time, although you will need to add either a `price` or `resid` column to the non-numeric dataframe in order to see its correlations with the non-numeric predictors.

```{r}
houses_tidy_nonnumeric$price <- housing_sales_clean$price

```

<details>
<summary>**Hints**</summary>
```{r, eval=FALSE}
houses_tidy_numeric <- housing_sales_clean %>%
  select_if(is.numeric)

houses_tidy_nonnumeric <- housing_sales_clean %>%
  select_if(function(x) !is.numeric(x))

houses_tidy_nonnumeric$price <- housing_sales_clean$price

ggpairs(houses_tidy_numeric, progress = F)
ggpairs(houses_tidy_nonnumeric,  progress = F)



```
and the same in subsequent rounds of predictor selection with the `resid` column.<br><br>
Remember, if you are not sure whether including a categorical predictor is statistically justified, run an `anova()` test passing in the models with- and without the categorical predictor and check the p-value of the test.
</details>

```{r}

modelh4 <- lm(price ~ sqft_lot, houses_tidy_numeric)
modelh5 <- lm(price ~ floors, houses_tidy_numeric)
modelh6 <- lm(price ~ yr_renovated, houses_tidy_nonnumeric)

autoplot(modelh4)
autoplot(modelh5)
autoplot(modelh6)

summary(modelh4)
summary(modelh5)
summary(modelh6)


```
```{r}
modelh <- lm(price ~ bedrooms, houses_tidy_numeric)
modelh2 <- lm(price ~ bathrooms, houses_tidy_numeric)
modelh3 <- lm(price ~ waterfront, houses_tidy_nonnumeric)

autoplot(modelh)
autoplot(modelh2)
autoplot(modelh3)
```

```{r}

model7 <- lm(price ~ grade, houses_tidy_nonnumeric)

summary(model7)

```


you could group? but you can group like top grade and bottom grade


```{r}

modelg_s <- lm(price ~ sqft_above + grade, housing_sales_clean)

summary(modelg_s)


anova(model7, modelg_s)
```

so keeping all grades is better 


```{r}

housing_sales_clean_grade_group <- housing_sales %>% 
  mutate(grade_group = as.factor(if_else(as.numeric(grade) < 8, 7, as.numeric(grade))))

```

```{r}
new_grade_m <- lm(price ~ grade, housing_sales)
summary(new_grade_m)
```


# Extensions

* Consider possible interactions between your four main effect predictors and test their effect upon $r^2$. Choose your best candidate interaction and visualise its effect. 

* Calculate the relative importance of predictors from your best $4$-predictor model (i.e. the model without an interaction). Which predictor affects `price` most strongly?



Whats is the data show me and what can i make a model of 

**what does 1 row represent?**

1 house 
making a model for individual house prices

**look at the data and variables**

Which of these things will be usfal 
feature engineering 
- taking the raw materials and making them more useful 

- might want to do a log transfer on data postive skew data (skimr)


```{r}

skimr::skim(housing_sales_clean)

```

```{r}

housing_sales_clean %>% 
  ggplot(aes(price)) +
  geom_histogram() +
  scale_x_continuous(trans = "log10")

```

This looks like a better model 

```{r}
house_log <-
housing_sales_clean %>% 
  mutate(ln_house_price = log(price))
```
is its not a linner realtion ship ( can you put a straight line thought and be correct) - for like grade no as grade 9 is not 3 times grade 3 so thats why you make it a factor 


making ggpear better

save it 
but has to rigth after the plot has outputted 
```{r}

ggpairs(houses_tidy_numeric, progress = F)
ggpairs(houses_tidy_nonnumeric,  progress = F)


ggsave("ggpairs_num.png",
       width = 15,
       height = 15)

```

from the atuoplots 

```{r}
plot(model)
```


we want to be abround 0 as we dont want anything to see we are wrong 

so what  - is the model ready - or is it the right type of model?

first plot
there is a patteren which we dont wont 

second 
- test of your residuals - there is a skew in our errors 
- looking for norailty in our trsiduals 

third 

what a straight line 


## adding reciduals back


```{r}

houses_model <- housing_sales_clean %>% 
  mutate(resid = model7$residuals)

```


```{r}

houses_model <- housing_sales_clean %>% 
  add_residuals(mode17)

```

this is good as can see how wrong you are, 

Also the part i havent explained yet 

so model now has grade and sqft but what else could I add to make it better thats why you add the resid back  


so what, what now?

Understand the process better 

It proves what you might think, 
so yes you can see grade and sqft_above have a an affect on the price 

- and in real world so if i want to see what i can charge for house with certain sqft 


- can be used as a predicitive model 


jamies code

```{r}
mod1b <- lm(price ~ grade_grouped, data = houses_tidy)
summary(mod1b)

mod2 <- lm(price ~ sqft_above + grade, data = houses_tidy)
summary(mod2)

houses_tidy <- houses_tidy %>%
  mutate(grade_grouped = as.factor(if_else(as.numeric(grade) < 8, 7, as.numeric(grade))))

anova(mod1a, mod2)
```

